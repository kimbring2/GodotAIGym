{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_cells.get_initial_state(batch_size=1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_output:  (<tf.Tensor: shape=(2, 128), dtype=float32, numpy=\n",
      "array([[ 1.02849394e-01, -3.64125073e-02, -7.51350671e-02,\n",
      "        -1.42729133e-01,  1.30299643e-01,  3.64783928e-02,\n",
      "         2.49019876e-01, -5.94914258e-02,  9.30734817e-03,\n",
      "        -1.45292446e-01,  1.03589945e-01, -1.29420519e-01,\n",
      "        -8.62171873e-02, -1.51720047e-01, -1.13675460e-01,\n",
      "        -2.35854089e-01,  2.03298237e-02, -1.40412590e-02,\n",
      "        -3.29783529e-01, -7.47002615e-03, -1.54086679e-01,\n",
      "        -1.79020494e-01,  5.61962873e-02,  1.94981415e-02,\n",
      "        -7.13001266e-02, -2.26844057e-01, -1.43006757e-01,\n",
      "        -9.67420191e-02, -3.61254299e-03, -1.55159831e-01,\n",
      "         8.03648606e-02, -2.27837078e-02, -7.00157583e-02,\n",
      "         2.87210764e-06,  1.35928199e-01,  3.16844927e-03,\n",
      "        -9.63403359e-02, -5.82029484e-02, -6.96222112e-02,\n",
      "         2.35813454e-01,  1.81506783e-01,  2.62233261e-02,\n",
      "         5.87270297e-02, -1.40106037e-01,  2.51356177e-02,\n",
      "        -1.27384260e-01, -1.21019334e-02,  1.69247746e-01,\n",
      "        -7.34903067e-02, -7.36720264e-02, -2.52915114e-01,\n",
      "        -1.10332131e-01, -5.20796999e-02, -4.99269515e-02,\n",
      "        -5.12663983e-02, -1.31792635e-01, -6.89684153e-02,\n",
      "         1.02496020e-01, -2.52405316e-01, -2.63420176e-02,\n",
      "         1.29006222e-01, -2.73655541e-02, -6.81434274e-02,\n",
      "        -8.09428543e-02,  6.46200217e-03,  3.79226096e-02,\n",
      "         5.42723946e-02, -3.90136279e-02, -5.29931895e-02,\n",
      "        -5.39775416e-02,  1.37938317e-02,  2.83524096e-01,\n",
      "         8.20882171e-02, -4.86265570e-02,  2.52333079e-02,\n",
      "         7.38533810e-02, -8.09253752e-02,  1.54979095e-01,\n",
      "         4.25154045e-02, -3.52784187e-01, -2.94761751e-02,\n",
      "        -2.69050032e-01, -3.55895050e-02,  5.60810715e-02,\n",
      "         1.17592789e-01, -1.46578193e-01,  1.71426699e-01,\n",
      "         2.40544118e-02, -2.86602914e-01,  1.09615192e-01,\n",
      "         1.91223755e-01,  7.57020190e-02,  1.05456494e-01,\n",
      "        -2.06839398e-01,  1.67909250e-01, -8.77096578e-02,\n",
      "        -3.73376161e-02, -7.20124468e-02, -2.03312766e-02,\n",
      "         4.55533229e-02,  1.52223587e-01, -8.36216472e-03,\n",
      "         3.69541347e-02,  6.87021613e-02,  7.77174234e-02,\n",
      "        -7.32845664e-02, -5.59817068e-02, -1.81003317e-01,\n",
      "         1.92744266e-02,  1.38583392e-01, -6.03161007e-02,\n",
      "         1.51086450e-01,  8.42706263e-02, -4.86585386e-02,\n",
      "        -2.46365324e-01,  5.53015023e-02, -1.40376508e-01,\n",
      "        -3.13346181e-03, -1.44067153e-01,  1.33899093e-01,\n",
      "         3.69085670e-02, -8.06108490e-02, -1.48700833e-01,\n",
      "         3.38210724e-02, -1.86062098e-01, -3.61608714e-03,\n",
      "         7.82263055e-02,  1.42709717e-01],\n",
      "       [ 1.02849394e-01, -3.64125073e-02, -7.51350671e-02,\n",
      "        -1.42729133e-01,  1.30299643e-01,  3.64783928e-02,\n",
      "         2.49019876e-01, -5.94914258e-02,  9.30734817e-03,\n",
      "        -1.45292446e-01,  1.03589945e-01, -1.29420519e-01,\n",
      "        -8.62171873e-02, -1.51720047e-01, -1.13675460e-01,\n",
      "        -2.35854089e-01,  2.03298237e-02, -1.40412590e-02,\n",
      "        -3.29783529e-01, -7.47002615e-03, -1.54086679e-01,\n",
      "        -1.79020494e-01,  5.61962873e-02,  1.94981415e-02,\n",
      "        -7.13001266e-02, -2.26844057e-01, -1.43006757e-01,\n",
      "        -9.67420191e-02, -3.61254299e-03, -1.55159831e-01,\n",
      "         8.03648606e-02, -2.27837078e-02, -7.00157583e-02,\n",
      "         2.87210764e-06,  1.35928199e-01,  3.16844927e-03,\n",
      "        -9.63403359e-02, -5.82029484e-02, -6.96222112e-02,\n",
      "         2.35813454e-01,  1.81506783e-01,  2.62233261e-02,\n",
      "         5.87270297e-02, -1.40106037e-01,  2.51356177e-02,\n",
      "        -1.27384260e-01, -1.21019334e-02,  1.69247746e-01,\n",
      "        -7.34903067e-02, -7.36720264e-02, -2.52915114e-01,\n",
      "        -1.10332131e-01, -5.20796999e-02, -4.99269515e-02,\n",
      "        -5.12663983e-02, -1.31792635e-01, -6.89684153e-02,\n",
      "         1.02496020e-01, -2.52405316e-01, -2.63420176e-02,\n",
      "         1.29006222e-01, -2.73655541e-02, -6.81434274e-02,\n",
      "        -8.09428543e-02,  6.46200217e-03,  3.79226096e-02,\n",
      "         5.42723946e-02, -3.90136279e-02, -5.29931895e-02,\n",
      "        -5.39775416e-02,  1.37938317e-02,  2.83524096e-01,\n",
      "         8.20882171e-02, -4.86265570e-02,  2.52333079e-02,\n",
      "         7.38533810e-02, -8.09253752e-02,  1.54979095e-01,\n",
      "         4.25154045e-02, -3.52784187e-01, -2.94761751e-02,\n",
      "        -2.69050032e-01, -3.55895050e-02,  5.60810715e-02,\n",
      "         1.17592789e-01, -1.46578193e-01,  1.71426699e-01,\n",
      "         2.40544118e-02, -2.86602914e-01,  1.09615192e-01,\n",
      "         1.91223755e-01,  7.57020190e-02,  1.05456494e-01,\n",
      "        -2.06839398e-01,  1.67909250e-01, -8.77096578e-02,\n",
      "        -3.73376161e-02, -7.20124468e-02, -2.03312766e-02,\n",
      "         4.55533229e-02,  1.52223587e-01, -8.36216472e-03,\n",
      "         3.69541347e-02,  6.87021613e-02,  7.77174234e-02,\n",
      "        -7.32845664e-02, -5.59817068e-02, -1.81003317e-01,\n",
      "         1.92744266e-02,  1.38583392e-01, -6.03161007e-02,\n",
      "         1.51086450e-01,  8.42706263e-02, -4.86585386e-02,\n",
      "        -2.46365324e-01,  5.53015023e-02, -1.40376508e-01,\n",
      "        -3.13346181e-03, -1.44067153e-01,  1.33899093e-01,\n",
      "         3.69085670e-02, -8.06108490e-02, -1.48700833e-01,\n",
      "         3.38210724e-02, -1.86062098e-01, -3.61608714e-03,\n",
      "         7.82263055e-02,  1.42709717e-01]], dtype=float32)>, [<tf.Tensor: shape=(2, 128), dtype=float32, numpy=\n",
      "array([[ 1.02849394e-01, -3.64125073e-02, -7.51350671e-02,\n",
      "        -1.42729133e-01,  1.30299643e-01,  3.64783928e-02,\n",
      "         2.49019876e-01, -5.94914258e-02,  9.30734817e-03,\n",
      "        -1.45292446e-01,  1.03589945e-01, -1.29420519e-01,\n",
      "        -8.62171873e-02, -1.51720047e-01, -1.13675460e-01,\n",
      "        -2.35854089e-01,  2.03298237e-02, -1.40412590e-02,\n",
      "        -3.29783529e-01, -7.47002615e-03, -1.54086679e-01,\n",
      "        -1.79020494e-01,  5.61962873e-02,  1.94981415e-02,\n",
      "        -7.13001266e-02, -2.26844057e-01, -1.43006757e-01,\n",
      "        -9.67420191e-02, -3.61254299e-03, -1.55159831e-01,\n",
      "         8.03648606e-02, -2.27837078e-02, -7.00157583e-02,\n",
      "         2.87210764e-06,  1.35928199e-01,  3.16844927e-03,\n",
      "        -9.63403359e-02, -5.82029484e-02, -6.96222112e-02,\n",
      "         2.35813454e-01,  1.81506783e-01,  2.62233261e-02,\n",
      "         5.87270297e-02, -1.40106037e-01,  2.51356177e-02,\n",
      "        -1.27384260e-01, -1.21019334e-02,  1.69247746e-01,\n",
      "        -7.34903067e-02, -7.36720264e-02, -2.52915114e-01,\n",
      "        -1.10332131e-01, -5.20796999e-02, -4.99269515e-02,\n",
      "        -5.12663983e-02, -1.31792635e-01, -6.89684153e-02,\n",
      "         1.02496020e-01, -2.52405316e-01, -2.63420176e-02,\n",
      "         1.29006222e-01, -2.73655541e-02, -6.81434274e-02,\n",
      "        -8.09428543e-02,  6.46200217e-03,  3.79226096e-02,\n",
      "         5.42723946e-02, -3.90136279e-02, -5.29931895e-02,\n",
      "        -5.39775416e-02,  1.37938317e-02,  2.83524096e-01,\n",
      "         8.20882171e-02, -4.86265570e-02,  2.52333079e-02,\n",
      "         7.38533810e-02, -8.09253752e-02,  1.54979095e-01,\n",
      "         4.25154045e-02, -3.52784187e-01, -2.94761751e-02,\n",
      "        -2.69050032e-01, -3.55895050e-02,  5.60810715e-02,\n",
      "         1.17592789e-01, -1.46578193e-01,  1.71426699e-01,\n",
      "         2.40544118e-02, -2.86602914e-01,  1.09615192e-01,\n",
      "         1.91223755e-01,  7.57020190e-02,  1.05456494e-01,\n",
      "        -2.06839398e-01,  1.67909250e-01, -8.77096578e-02,\n",
      "        -3.73376161e-02, -7.20124468e-02, -2.03312766e-02,\n",
      "         4.55533229e-02,  1.52223587e-01, -8.36216472e-03,\n",
      "         3.69541347e-02,  6.87021613e-02,  7.77174234e-02,\n",
      "        -7.32845664e-02, -5.59817068e-02, -1.81003317e-01,\n",
      "         1.92744266e-02,  1.38583392e-01, -6.03161007e-02,\n",
      "         1.51086450e-01,  8.42706263e-02, -4.86585386e-02,\n",
      "        -2.46365324e-01,  5.53015023e-02, -1.40376508e-01,\n",
      "        -3.13346181e-03, -1.44067153e-01,  1.33899093e-01,\n",
      "         3.69085670e-02, -8.06108490e-02, -1.48700833e-01,\n",
      "         3.38210724e-02, -1.86062098e-01, -3.61608714e-03,\n",
      "         7.82263055e-02,  1.42709717e-01],\n",
      "       [ 1.02849394e-01, -3.64125073e-02, -7.51350671e-02,\n",
      "        -1.42729133e-01,  1.30299643e-01,  3.64783928e-02,\n",
      "         2.49019876e-01, -5.94914258e-02,  9.30734817e-03,\n",
      "        -1.45292446e-01,  1.03589945e-01, -1.29420519e-01,\n",
      "        -8.62171873e-02, -1.51720047e-01, -1.13675460e-01,\n",
      "        -2.35854089e-01,  2.03298237e-02, -1.40412590e-02,\n",
      "        -3.29783529e-01, -7.47002615e-03, -1.54086679e-01,\n",
      "        -1.79020494e-01,  5.61962873e-02,  1.94981415e-02,\n",
      "        -7.13001266e-02, -2.26844057e-01, -1.43006757e-01,\n",
      "        -9.67420191e-02, -3.61254299e-03, -1.55159831e-01,\n",
      "         8.03648606e-02, -2.27837078e-02, -7.00157583e-02,\n",
      "         2.87210764e-06,  1.35928199e-01,  3.16844927e-03,\n",
      "        -9.63403359e-02, -5.82029484e-02, -6.96222112e-02,\n",
      "         2.35813454e-01,  1.81506783e-01,  2.62233261e-02,\n",
      "         5.87270297e-02, -1.40106037e-01,  2.51356177e-02,\n",
      "        -1.27384260e-01, -1.21019334e-02,  1.69247746e-01,\n",
      "        -7.34903067e-02, -7.36720264e-02, -2.52915114e-01,\n",
      "        -1.10332131e-01, -5.20796999e-02, -4.99269515e-02,\n",
      "        -5.12663983e-02, -1.31792635e-01, -6.89684153e-02,\n",
      "         1.02496020e-01, -2.52405316e-01, -2.63420176e-02,\n",
      "         1.29006222e-01, -2.73655541e-02, -6.81434274e-02,\n",
      "        -8.09428543e-02,  6.46200217e-03,  3.79226096e-02,\n",
      "         5.42723946e-02, -3.90136279e-02, -5.29931895e-02,\n",
      "        -5.39775416e-02,  1.37938317e-02,  2.83524096e-01,\n",
      "         8.20882171e-02, -4.86265570e-02,  2.52333079e-02,\n",
      "         7.38533810e-02, -8.09253752e-02,  1.54979095e-01,\n",
      "         4.25154045e-02, -3.52784187e-01, -2.94761751e-02,\n",
      "        -2.69050032e-01, -3.55895050e-02,  5.60810715e-02,\n",
      "         1.17592789e-01, -1.46578193e-01,  1.71426699e-01,\n",
      "         2.40544118e-02, -2.86602914e-01,  1.09615192e-01,\n",
      "         1.91223755e-01,  7.57020190e-02,  1.05456494e-01,\n",
      "        -2.06839398e-01,  1.67909250e-01, -8.77096578e-02,\n",
      "        -3.73376161e-02, -7.20124468e-02, -2.03312766e-02,\n",
      "         4.55533229e-02,  1.52223587e-01, -8.36216472e-03,\n",
      "         3.69541347e-02,  6.87021613e-02,  7.77174234e-02,\n",
      "        -7.32845664e-02, -5.59817068e-02, -1.81003317e-01,\n",
      "         1.92744266e-02,  1.38583392e-01, -6.03161007e-02,\n",
      "         1.51086450e-01,  8.42706263e-02, -4.86585386e-02,\n",
      "        -2.46365324e-01,  5.53015023e-02, -1.40376508e-01,\n",
      "        -3.13346181e-03, -1.44067153e-01,  1.33899093e-01,\n",
      "         3.69085670e-02, -8.06108490e-02, -1.48700833e-01,\n",
      "         3.38210724e-02, -1.86062098e-01, -3.61608714e-03,\n",
      "         7.82263055e-02,  1.42709717e-01]], dtype=float32)>, <tf.Tensor: shape=(2, 128), dtype=float32, numpy=\n",
      "array([[ 1.40430138e-01, -5.55530488e-02, -1.50443718e-01,\n",
      "        -2.52534539e-01,  3.36058706e-01,  7.94784129e-02,\n",
      "         4.20550615e-01, -2.27024674e-01,  3.32587585e-02,\n",
      "        -3.89466345e-01,  1.88385546e-01, -2.37118751e-01,\n",
      "        -1.54940993e-01, -2.47647449e-01, -2.50000745e-01,\n",
      "        -3.03298950e-01,  5.45345396e-02, -5.64757474e-02,\n",
      "        -4.57710713e-01, -1.26679568e-02, -2.20368370e-01,\n",
      "        -2.90821403e-01,  2.43943483e-01,  2.86917761e-02,\n",
      "        -1.11794703e-01, -4.10350174e-01, -2.40750819e-01,\n",
      "        -2.98040986e-01, -1.58500522e-02, -3.66146713e-01,\n",
      "         1.92708731e-01, -5.30023724e-02, -1.25638589e-01,\n",
      "         7.06069704e-06,  2.86215037e-01,  5.94562385e-03,\n",
      "        -3.09518009e-01, -1.63620681e-01, -1.18735947e-01,\n",
      "         5.06146967e-01,  3.94591480e-01,  7.92741254e-02,\n",
      "         1.79892004e-01, -1.71076909e-01,  4.20265421e-02,\n",
      "        -2.75345236e-01, -2.71796901e-02,  3.79154235e-01,\n",
      "        -1.57223716e-01, -1.60548389e-01, -3.78716946e-01,\n",
      "        -5.64527035e-01, -1.26536071e-01, -1.49795607e-01,\n",
      "        -1.25178337e-01, -3.77233356e-01, -1.16784945e-01,\n",
      "         1.61147848e-01, -5.08794010e-01, -9.24828798e-02,\n",
      "         2.26573214e-01, -6.82330951e-02, -1.57948345e-01,\n",
      "        -2.93018907e-01,  1.80600025e-02,  1.08865999e-01,\n",
      "         1.01247154e-01, -1.19212255e-01, -1.19919054e-01,\n",
      "        -1.31571025e-01,  2.36512143e-02,  4.34059978e-01,\n",
      "         1.42430201e-01, -9.51988474e-02,  3.94092649e-02,\n",
      "         3.03002983e-01, -1.67891979e-01,  4.36494678e-01,\n",
      "         8.81589055e-02, -5.19573569e-01, -5.44370674e-02,\n",
      "        -3.89473736e-01, -1.11828536e-01,  3.44855577e-01,\n",
      "         2.88190335e-01, -2.19898239e-01,  2.38304883e-01,\n",
      "         4.11707573e-02, -5.32891273e-01,  1.58137605e-01,\n",
      "         3.32953423e-01,  1.34763390e-01,  2.30646774e-01,\n",
      "        -3.38196367e-01,  2.98929125e-01, -1.50205404e-01,\n",
      "        -7.41740242e-02, -1.69579074e-01, -3.77824791e-02,\n",
      "         1.63889766e-01,  2.60764092e-01, -1.70440730e-02,\n",
      "         1.16193727e-01,  1.94151342e-01,  1.11860707e-01,\n",
      "        -1.48792803e-01, -1.39223054e-01, -2.78222322e-01,\n",
      "         4.12722193e-02,  2.98449516e-01, -1.06346644e-01,\n",
      "         2.60936946e-01,  2.05871344e-01, -1.10461868e-01,\n",
      "        -6.67073786e-01,  2.59767652e-01, -4.11435753e-01,\n",
      "        -9.21478216e-03, -2.24448472e-01,  3.26877505e-01,\n",
      "         6.27358034e-02, -2.84140497e-01, -3.19691032e-01,\n",
      "         7.13727772e-02, -3.09573352e-01, -9.34339967e-03,\n",
      "         2.32144102e-01,  3.46792430e-01],\n",
      "       [ 1.40430138e-01, -5.55530488e-02, -1.50443718e-01,\n",
      "        -2.52534539e-01,  3.36058706e-01,  7.94784129e-02,\n",
      "         4.20550615e-01, -2.27024674e-01,  3.32587585e-02,\n",
      "        -3.89466345e-01,  1.88385546e-01, -2.37118751e-01,\n",
      "        -1.54940993e-01, -2.47647449e-01, -2.50000745e-01,\n",
      "        -3.03298950e-01,  5.45345396e-02, -5.64757474e-02,\n",
      "        -4.57710713e-01, -1.26679568e-02, -2.20368370e-01,\n",
      "        -2.90821403e-01,  2.43943483e-01,  2.86917761e-02,\n",
      "        -1.11794703e-01, -4.10350174e-01, -2.40750819e-01,\n",
      "        -2.98040986e-01, -1.58500522e-02, -3.66146713e-01,\n",
      "         1.92708731e-01, -5.30023724e-02, -1.25638589e-01,\n",
      "         7.06069704e-06,  2.86215037e-01,  5.94562385e-03,\n",
      "        -3.09518009e-01, -1.63620681e-01, -1.18735947e-01,\n",
      "         5.06146967e-01,  3.94591480e-01,  7.92741254e-02,\n",
      "         1.79892004e-01, -1.71076909e-01,  4.20265421e-02,\n",
      "        -2.75345236e-01, -2.71796901e-02,  3.79154235e-01,\n",
      "        -1.57223716e-01, -1.60548389e-01, -3.78716946e-01,\n",
      "        -5.64527035e-01, -1.26536071e-01, -1.49795607e-01,\n",
      "        -1.25178337e-01, -3.77233356e-01, -1.16784945e-01,\n",
      "         1.61147848e-01, -5.08794010e-01, -9.24828798e-02,\n",
      "         2.26573214e-01, -6.82330951e-02, -1.57948345e-01,\n",
      "        -2.93018907e-01,  1.80600025e-02,  1.08865999e-01,\n",
      "         1.01247154e-01, -1.19212255e-01, -1.19919054e-01,\n",
      "        -1.31571025e-01,  2.36512143e-02,  4.34059978e-01,\n",
      "         1.42430201e-01, -9.51988474e-02,  3.94092649e-02,\n",
      "         3.03002983e-01, -1.67891979e-01,  4.36494678e-01,\n",
      "         8.81589055e-02, -5.19573569e-01, -5.44370674e-02,\n",
      "        -3.89473736e-01, -1.11828536e-01,  3.44855577e-01,\n",
      "         2.88190335e-01, -2.19898239e-01,  2.38304883e-01,\n",
      "         4.11707573e-02, -5.32891273e-01,  1.58137605e-01,\n",
      "         3.32953423e-01,  1.34763390e-01,  2.30646774e-01,\n",
      "        -3.38196367e-01,  2.98929125e-01, -1.50205404e-01,\n",
      "        -7.41740242e-02, -1.69579074e-01, -3.77824791e-02,\n",
      "         1.63889766e-01,  2.60764092e-01, -1.70440730e-02,\n",
      "         1.16193727e-01,  1.94151342e-01,  1.11860707e-01,\n",
      "        -1.48792803e-01, -1.39223054e-01, -2.78222322e-01,\n",
      "         4.12722193e-02,  2.98449516e-01, -1.06346644e-01,\n",
      "         2.60936946e-01,  2.05871344e-01, -1.10461868e-01,\n",
      "        -6.67073786e-01,  2.59767652e-01, -4.11435753e-01,\n",
      "        -9.21478216e-03, -2.24448472e-01,  3.26877505e-01,\n",
      "         6.27358034e-02, -2.84140497e-01, -3.19691032e-01,\n",
      "         7.13727772e-02, -3.09573352e-01, -9.34339967e-03,\n",
      "         2.32144102e-01,  3.46792430e-01]], dtype=float32)>])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "batch_size = 3\n",
    "sentence_max_length = 5\n",
    "n_features = 2\n",
    "new_shape = (batch_size, sentence_max_length, n_features)\n",
    "x = tf.constant(np.reshape(np.arange(30), new_shape), dtype = tf.float32)\n",
    "\n",
    "lstm_cells = tf.keras.layers.LSTMCell(128)\n",
    "\n",
    "test_input = np.ones((2,128))\n",
    "\n",
    "states = lstm_cells.get_initial_state(batch_size=1, dtype=tf.float32)\n",
    "test_output = lstm_cells(test_input, states)\n",
    "print(\"test_output: \", test_output)\n",
    "\n",
    "#rnn_cells = [tf.keras.layers.LSTMCell(128) for _ in range(1)]\n",
    "#stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n",
    "\n",
    "#initial_state = stacked_lstm.get_initial_state(batch_size=4, dtype=tf.float32)\n",
    "#initial_state\n",
    "#lstm_layer = tf.keras.layers.RNN(stacked_lstm)\n",
    "\n",
    "#result = lstm_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KzsUo6vMbPg3",
    "outputId": "7844c79a-ea20-4361-d055-9fffb99504af",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/2000000, thread: 0, score: -21.0, average: -21.00 SAVING\n",
      "episode: 1/2000000, thread: 0, score: -21.0, average: -21.00 SAVING\n",
      "episode: 2/2000000, thread: 0, score: -19.0, average: -20.33 SAVING\n",
      "episode: 3/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 4/2000000, thread: 0, score: -21.0, average: -20.60 \n",
      "episode: 5/2000000, thread: 0, score: -21.0, average: -20.67 \n",
      "episode: 6/2000000, thread: 0, score: -21.0, average: -20.71 \n",
      "episode: 7/2000000, thread: 0, score: -18.0, average: -20.38 \n",
      "episode: 8/2000000, thread: 0, score: -20.0, average: -20.33 SAVING\n",
      "episode: 9/2000000, thread: 0, score: -20.0, average: -20.30 SAVING\n",
      "episode: 10/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 11/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 12/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 13/2000000, thread: 0, score: -19.0, average: -20.36 \n",
      "episode: 14/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 15/2000000, thread: 0, score: -19.0, average: -20.31 \n",
      "episode: 16/2000000, thread: 0, score: -21.0, average: -20.35 \n",
      "episode: 17/2000000, thread: 0, score: -20.0, average: -20.33 \n",
      "episode: 18/2000000, thread: 0, score: -21.0, average: -20.37 \n",
      "episode: 19/2000000, thread: 0, score: -20.0, average: -20.35 \n",
      "episode: 20/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 21/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 22/2000000, thread: 0, score: -20.0, average: -20.35 \n",
      "episode: 23/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 24/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 25/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 26/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 27/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 28/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 29/2000000, thread: 0, score: -17.0, average: -20.37 \n",
      "episode: 30/2000000, thread: 0, score: -21.0, average: -20.39 \n",
      "episode: 31/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 32/2000000, thread: 0, score: -21.0, average: -20.39 \n",
      "episode: 33/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 34/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 35/2000000, thread: 0, score: -19.0, average: -20.36 \n",
      "episode: 36/2000000, thread: 0, score: -19.0, average: -20.32 \n",
      "episode: 37/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "episode: 38/2000000, thread: 0, score: -20.0, average: -20.33 \n",
      "episode: 39/2000000, thread: 0, score: -21.0, average: -20.35 \n",
      "episode: 40/2000000, thread: 0, score: -21.0, average: -20.37 \n",
      "episode: 41/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 42/2000000, thread: 0, score: -20.0, average: -20.37 \n",
      "episode: 43/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 44/2000000, thread: 0, score: -19.0, average: -20.33 \n",
      "episode: 45/2000000, thread: 0, score: -21.0, average: -20.35 \n",
      "episode: 46/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 47/2000000, thread: 0, score: -20.0, average: -20.35 \n",
      "episode: 48/2000000, thread: 0, score: -21.0, average: -20.37 \n",
      "episode: 49/2000000, thread: 0, score: -17.0, average: -20.30 SAVING\n",
      "episode: 50/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 51/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 52/2000000, thread: 0, score: -19.0, average: -20.30 SAVING\n",
      "episode: 53/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 54/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 55/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 56/2000000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "episode: 57/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 58/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 59/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 60/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 61/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 62/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 63/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 64/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 65/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "episode: 66/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 67/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 68/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 69/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "episode: 70/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 71/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 72/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 73/2000000, thread: 0, score: -20.0, average: -20.40 \n",
      "episode: 74/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 75/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 76/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 77/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 78/2000000, thread: 0, score: -20.0, average: -20.32 \n",
      "episode: 79/2000000, thread: 0, score: -19.0, average: -20.36 \n",
      "episode: 80/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 81/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 82/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 83/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 84/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 85/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 86/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "episode: 87/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 88/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 89/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 90/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "episode: 91/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 92/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 93/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 94/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 95/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 96/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 97/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 98/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 99/2000000, thread: 0, score: -21.0, average: -20.60 \n",
      "episode: 100/2000000, thread: 0, score: -20.0, average: -20.58 \n",
      "episode: 101/2000000, thread: 0, score: -20.0, average: -20.56 \n",
      "episode: 102/2000000, thread: 0, score: -21.0, average: -20.60 \n",
      "episode: 103/2000000, thread: 0, score: -21.0, average: -20.60 \n",
      "episode: 104/2000000, thread: 0, score: -21.0, average: -20.60 \n",
      "episode: 105/2000000, thread: 0, score: -18.0, average: -20.54 \n",
      "episode: 106/2000000, thread: 0, score: -20.0, average: -20.52 \n",
      "episode: 107/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 108/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 109/2000000, thread: 0, score: -19.0, average: -20.48 \n",
      "episode: 110/2000000, thread: 0, score: -20.0, average: -20.46 \n",
      "episode: 111/2000000, thread: 0, score: -18.0, average: -20.40 \n",
      "episode: 112/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 113/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 114/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 115/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 116/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 117/2000000, thread: 0, score: -19.0, average: -20.38 \n",
      "episode: 118/2000000, thread: 0, score: -19.0, average: -20.34 \n",
      "episode: 119/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 120/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 121/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 122/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 123/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 124/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 125/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 126/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 127/2000000, thread: 0, score: -19.0, average: -20.38 \n",
      "episode: 128/2000000, thread: 0, score: -20.0, average: -20.38 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 129/2000000, thread: 0, score: -20.0, average: -20.40 \n",
      "episode: 130/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 131/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 132/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 133/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 134/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "episode: 135/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 136/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 137/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 138/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 139/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 140/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 141/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 142/2000000, thread: 0, score: -20.0, average: -20.40 \n",
      "episode: 143/2000000, thread: 0, score: -19.0, average: -20.36 \n",
      "episode: 144/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 145/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 146/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 147/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 148/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "episode: 149/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "episode: 150/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "episode: 151/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 152/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 153/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 154/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 155/2000000, thread: 0, score: -19.0, average: -20.38 \n",
      "episode: 156/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "episode: 157/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 158/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "episode: 159/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "episode: 160/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 161/2000000, thread: 0, score: -21.0, average: -20.54 \n",
      "episode: 162/2000000, thread: 0, score: -20.0, average: -20.52 \n",
      "episode: 163/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 164/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 165/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 166/2000000, thread: 0, score: -18.0, average: -20.44 \n",
      "episode: 167/2000000, thread: 0, score: -20.0, average: -20.46 \n",
      "episode: 168/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 169/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 170/2000000, thread: 0, score: -20.0, average: -20.52 \n",
      "episode: 171/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 172/2000000, thread: 0, score: -20.0, average: -20.50 \n",
      "episode: 173/2000000, thread: 0, score: -20.0, average: -20.48 \n",
      "episode: 174/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 175/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 176/2000000, thread: 0, score: -18.0, average: -20.44 \n",
      "episode: 177/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 178/2000000, thread: 0, score: -21.0, average: -20.50 \n",
      "episode: 179/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 180/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 181/2000000, thread: 0, score: -21.0, average: -20.52 \n",
      "episode: 182/2000000, thread: 0, score: -19.0, average: -20.48 \n",
      "episode: 183/2000000, thread: 0, score: -21.0, average: -20.48 \n",
      "episode: 184/2000000, thread: 0, score: -20.0, average: -20.48 \n",
      "episode: 185/2000000, thread: 0, score: -19.0, average: -20.44 \n",
      "episode: 186/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "episode: 187/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "episode: 188/2000000, thread: 0, score: -20.0, average: -20.40 \n",
      "episode: 189/2000000, thread: 0, score: -18.0, average: -20.34 \n",
      "episode: 190/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "episode: 191/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 192/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "episode: 193/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "episode: 194/2000000, thread: 0, score: -17.0, average: -20.30 SAVING\n",
      "episode: 195/2000000, thread: 0, score: -19.0, average: -20.26 SAVING\n",
      "episode: 196/2000000, thread: 0, score: -21.0, average: -20.28 \n",
      "episode: 197/2000000, thread: 0, score: -21.0, average: -20.30 \n",
      "episode: 198/2000000, thread: 0, score: -20.0, average: -20.28 \n",
      "episode: 199/2000000, thread: 0, score: -20.0, average: -20.26 SAVING\n",
      "episode: 200/2000000, thread: 0, score: -20.0, average: -20.24 SAVING\n",
      "episode: 201/2000000, thread: 0, score: -19.0, average: -20.20 SAVING\n",
      "episode: 202/2000000, thread: 0, score: -21.0, average: -20.20 SAVING\n",
      "episode: 203/2000000, thread: 0, score: -21.0, average: -20.20 SAVING\n",
      "episode: 204/2000000, thread: 0, score: -20.0, average: -20.20 SAVING\n",
      "episode: 205/2000000, thread: 0, score: -20.0, average: -20.22 \n",
      "episode: 206/2000000, thread: 0, score: -21.0, average: -20.22 \n",
      "episode: 207/2000000, thread: 0, score: -21.0, average: -20.22 \n",
      "episode: 208/2000000, thread: 0, score: -18.0, average: -20.16 SAVING\n",
      "episode: 209/2000000, thread: 0, score: -21.0, average: -20.16 SAVING\n",
      "episode: 210/2000000, thread: 0, score: -20.0, average: -20.14 SAVING\n",
      "episode: 211/2000000, thread: 0, score: -21.0, average: -20.14 SAVING\n",
      "episode: 212/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "episode: 213/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 214/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 215/2000000, thread: 0, score: -20.0, average: -20.14 SAVING\n",
      "episode: 216/2000000, thread: 0, score: -20.0, average: -20.18 \n",
      "episode: 217/2000000, thread: 0, score: -20.0, average: -20.18 \n",
      "episode: 218/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "episode: 219/2000000, thread: 0, score: -19.0, average: -20.14 SAVING\n",
      "episode: 220/2000000, thread: 0, score: -20.0, average: -20.14 SAVING\n",
      "episode: 221/2000000, thread: 0, score: -20.0, average: -20.14 SAVING\n",
      "episode: 222/2000000, thread: 0, score: -19.0, average: -20.12 SAVING\n",
      "episode: 223/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "episode: 224/2000000, thread: 0, score: -18.0, average: -20.08 SAVING\n",
      "episode: 225/2000000, thread: 0, score: -20.0, average: -20.06 SAVING\n",
      "episode: 226/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 227/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "episode: 228/2000000, thread: 0, score: -21.0, average: -20.08 \n",
      "episode: 229/2000000, thread: 0, score: -19.0, average: -20.04 SAVING\n",
      "episode: 230/2000000, thread: 0, score: -20.0, average: -20.02 SAVING\n",
      "episode: 231/2000000, thread: 0, score: -20.0, average: -20.00 SAVING\n",
      "episode: 232/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 233/2000000, thread: 0, score: -20.0, average: -20.00 SAVING\n",
      "episode: 234/2000000, thread: 0, score: -21.0, average: -20.02 \n",
      "episode: 235/2000000, thread: 0, score: -21.0, average: -20.06 \n",
      "episode: 236/2000000, thread: 0, score: -21.0, average: -20.06 \n",
      "episode: 237/2000000, thread: 0, score: -19.0, average: -20.04 \n",
      "episode: 238/2000000, thread: 0, score: -20.0, average: -20.04 \n",
      "episode: 239/2000000, thread: 0, score: -19.0, average: -20.06 \n",
      "episode: 240/2000000, thread: 0, score: -21.0, average: -20.06 \n",
      "episode: 241/2000000, thread: 0, score: -21.0, average: -20.08 \n",
      "episode: 242/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "episode: 243/2000000, thread: 0, score: -20.0, average: -20.06 \n",
      "episode: 244/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 245/2000000, thread: 0, score: -20.0, average: -20.14 \n",
      "episode: 246/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 247/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 248/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 249/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 250/2000000, thread: 0, score: -19.0, average: -20.10 \n",
      "episode: 251/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "episode: 252/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 253/2000000, thread: 0, score: -17.0, average: -20.04 \n",
      "episode: 254/2000000, thread: 0, score: -19.0, average: -20.02 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 255/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 256/2000000, thread: 0, score: -21.0, average: -20.02 \n",
      "episode: 257/2000000, thread: 0, score: -19.0, average: -19.98 SAVING\n",
      "episode: 258/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 259/2000000, thread: 0, score: -21.0, average: -20.02 \n",
      "episode: 260/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 261/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "episode: 262/2000000, thread: 0, score: -19.0, average: -19.96 SAVING\n",
      "episode: 263/2000000, thread: 0, score: -21.0, average: -19.98 \n",
      "episode: 264/2000000, thread: 0, score: -18.0, average: -19.94 SAVING\n",
      "episode: 265/2000000, thread: 0, score: -20.0, average: -19.94 SAVING\n",
      "episode: 266/2000000, thread: 0, score: -19.0, average: -19.92 SAVING\n",
      "episode: 267/2000000, thread: 0, score: -20.0, average: -19.92 SAVING\n",
      "episode: 268/2000000, thread: 0, score: -19.0, average: -19.88 SAVING\n",
      "episode: 269/2000000, thread: 0, score: -19.0, average: -19.88 SAVING\n",
      "episode: 270/2000000, thread: 0, score: -21.0, average: -19.90 \n",
      "episode: 271/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 272/2000000, thread: 0, score: -17.0, average: -19.88 SAVING\n",
      "episode: 273/2000000, thread: 0, score: -20.0, average: -19.86 SAVING\n",
      "episode: 274/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 275/2000000, thread: 0, score: -18.0, average: -19.88 \n",
      "episode: 276/2000000, thread: 0, score: -21.0, average: -19.90 \n",
      "episode: 277/2000000, thread: 0, score: -19.0, average: -19.88 \n",
      "episode: 278/2000000, thread: 0, score: -20.0, average: -19.86 SAVING\n",
      "episode: 279/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 280/2000000, thread: 0, score: -19.0, average: -19.86 SAVING\n",
      "episode: 281/2000000, thread: 0, score: -19.0, average: -19.84 SAVING\n",
      "episode: 282/2000000, thread: 0, score: -21.0, average: -19.86 \n",
      "episode: 283/2000000, thread: 0, score: -20.0, average: -19.86 \n",
      "episode: 284/2000000, thread: 0, score: -20.0, average: -19.84 SAVING\n",
      "episode: 285/2000000, thread: 0, score: -21.0, average: -19.84 SAVING\n",
      "episode: 286/2000000, thread: 0, score: -20.0, average: -19.82 SAVING\n",
      "episode: 287/2000000, thread: 0, score: -18.0, average: -19.80 SAVING\n",
      "episode: 288/2000000, thread: 0, score: -19.0, average: -19.78 SAVING\n",
      "episode: 289/2000000, thread: 0, score: -20.0, average: -19.80 \n",
      "episode: 290/2000000, thread: 0, score: -21.0, average: -19.80 \n",
      "episode: 291/2000000, thread: 0, score: -20.0, average: -19.78 SAVING\n",
      "episode: 292/2000000, thread: 0, score: -21.0, average: -19.80 \n",
      "episode: 293/2000000, thread: 0, score: -21.0, average: -19.82 \n",
      "episode: 294/2000000, thread: 0, score: -20.0, average: -19.82 \n",
      "episode: 295/2000000, thread: 0, score: -20.0, average: -19.82 \n",
      "episode: 296/2000000, thread: 0, score: -21.0, average: -19.84 \n",
      "episode: 297/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 298/2000000, thread: 0, score: -21.0, average: -19.84 \n",
      "episode: 299/2000000, thread: 0, score: -21.0, average: -19.84 \n",
      "episode: 300/2000000, thread: 0, score: -21.0, average: -19.88 \n",
      "episode: 301/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 302/2000000, thread: 0, score: -21.0, average: -19.86 \n",
      "episode: 303/2000000, thread: 0, score: -16.0, average: -19.84 \n",
      "episode: 304/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 305/2000000, thread: 0, score: -21.0, average: -19.86 \n",
      "episode: 306/2000000, thread: 0, score: -21.0, average: -19.86 \n",
      "episode: 307/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 308/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 309/2000000, thread: 0, score: -21.0, average: -19.88 \n",
      "episode: 310/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 311/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 312/2000000, thread: 0, score: -18.0, average: -19.86 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import threading\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "class OurModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape, action_space):\n",
    "        super(OurModel, self).__init__()\n",
    "        \n",
    "        self.dense_0 = Dense(512, activation='relu')\n",
    "        \n",
    "        self.core = tf.keras.layers.LSTMCell(128)\n",
    "        \n",
    "        self.dense_1 = Dense(action_space)\n",
    "        self.dense_2 = Dense(1)\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        return self.core.get_initial_state(batch_size=batch_size, dtype=tf.float32) \n",
    "    \n",
    "    def call(self, X_input, core_state):\n",
    "        # X_input.shape:  (1, 4, 80, 80)\n",
    "        \n",
    "        batch_size = X_input.shape[0]\n",
    "        #print(\"batch_size: \", batch_size)\n",
    "        #print(\"core_state: \", core_state)\n",
    "        \n",
    "        core_output_list = []\n",
    "        for i in tf.range(0, batch_size):\n",
    "            #X_input.shape:  (1, 4, 80, 80)\n",
    "            #batch_size:  1\n",
    "            #X_input[i].shape:  (4, 80, 80)\n",
    "            #Input.shape:  (4, 512)\n",
    "            #print(\"X_input[i].shape: \", X_input[i].shape)\n",
    "            \n",
    "            Input = tf.expand_dims(X_input[i], 0)\n",
    "            \n",
    "            Input = Flatten()(Input)\n",
    "            #print(\"Input.shape 1: \", Input.shape)\n",
    "            \n",
    "            Input = self.dense_0(Input)\n",
    "            #print(\"Input.shape 2: \", Input.shape)\n",
    "            \n",
    "            core_output, core_state = self.core(Input, core_state)\n",
    "            #core_output_flattened = Flatten()(core_output)\n",
    "            #print(\"core_output.shape: \", core_output.shape)\n",
    "            core_output_list.append(core_output)\n",
    "        \n",
    "        outputs = tf.stack(core_output_list)\n",
    "        #print(\"outputs.shape: \", outputs.shape)\n",
    "        \n",
    "        Ouput = Flatten()(outputs)\n",
    "        #print(\"Ouput.shape: \", Ouput.shape)\n",
    "        \n",
    "        #Ouput = self.dense_0(Ouput)\n",
    "        action_logit = self.dense_1(Ouput)\n",
    "        value = self.dense_2(Ouput)\n",
    "        \n",
    "        #print(\"core_state output: \", core_state)\n",
    "        \n",
    "        return action_logit, value, core_state\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "  \"\"\"Computes a safe logarithm which returns 0 if x is zero.\"\"\"\n",
    "  return tf.where(\n",
    "      tf.math.equal(x, 0),\n",
    "      tf.zeros_like(x),\n",
    "      tf.math.log(tf.math.maximum(1e-12, x)))\n",
    "\n",
    "\n",
    "def take_vector_elements(vectors, indices):\n",
    "    \"\"\"\n",
    "    For a batch of vectors, take a single vector component\n",
    "    out of each vector.\n",
    "    Args:\n",
    "      vectors: a [batch x dims] Tensor.\n",
    "      indices: an int32 Tensor with `batch` entries.\n",
    "    Returns:\n",
    "      A Tensor with `batch` entries, one for each vector.\n",
    "    \"\"\"\n",
    "    return tf.gather_nd(vectors, tf.stack([tf.range(tf.shape(vectors)[0]), indices], axis=1))\n",
    "\n",
    "\n",
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "\n",
    "class A3CAgent:\n",
    "    # Actor-Critic Main Optimization Algorithm\n",
    "    def __init__(self, env_name):\n",
    "        # Initialization\n",
    "        self.env_name = env_name       \n",
    "        self.env = gym.make(env_name)\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.EPISODES, self.episode, self.max_average = 2000000, 0, -21.0 # specific for pong\n",
    "        self.lock = Lock()\n",
    "        self.lr = 0.0001\n",
    "\n",
    "        self.ROWS = 80\n",
    "        self.COLS = 80\n",
    "        self.REM_STEP = 4\n",
    "\n",
    "        # Instantiate plot memory\n",
    "        self.scores, self.episodes, self.average = [], [], []\n",
    "\n",
    "        self.Save_Path = 'Models'\n",
    "        self.state_size = (self.REM_STEP, self.ROWS, self.COLS)\n",
    "        \n",
    "        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n",
    "        self.path = '{}_A3C_{}'.format(self.env_name, self.lr)\n",
    "        self.model_name = os.path.join(self.Save_Path, self.path)\n",
    "\n",
    "        # Create Actor-Critic network model\n",
    "        self.ActorCritic = OurModel(input_shape=self.state_size, action_space=self.action_size)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.lr)\n",
    "\n",
    "    def act(self, state, core_state):\n",
    "        # Use the network to predict the next action to take, using the model\n",
    "        prediction = self.ActorCritic(state, core_state, training=False)\n",
    "        action = tf.random.categorical(prediction[0], 1).numpy()\n",
    "\n",
    "        return action[0][0], prediction[2]\n",
    "\n",
    "    def discount_rewards(self, reward, dones):\n",
    "        # Compute the gamma-discounted rewards over an episode\n",
    "        gamma = 0.99    # discount rate\n",
    "        running_add = 0\n",
    "        discounted_r = np.zeros_like(reward)\n",
    "        for i in reversed(range(0, len(reward))):\n",
    "            if reward[i] != 0: # reset the sum, since this was a game boundary (pong specific!)\n",
    "                running_add = 0\n",
    "\n",
    "            running_add = running_add * gamma + reward[i]\n",
    "            discounted_r[i] = running_add\n",
    "\n",
    "        discounted_r -= np.mean(discounted_r) # normalizing the result\n",
    "        discounted_r /= np.std(discounted_r) # divide by standard deviation\n",
    "\n",
    "        return discounted_r\n",
    "        \n",
    "    def replay(self, states, actions, rewards, dones):\n",
    "        # reshape memory to appropriate shape for training\n",
    "        states = np.vstack(states)\n",
    "        \n",
    "        # Compute discounted rewards\n",
    "        discounted_r = self.discount_rewards(rewards, dones)\n",
    "        discounted_r_ = np.vstack(discounted_r)\n",
    "        with tf.GradientTape() as tape:\n",
    "            core_state = self.ActorCritic.initial_state(1)\n",
    "            prediction = self.ActorCritic(states, core_state, training=True)\n",
    "            action_logits = prediction[0]\n",
    "            values = prediction[1]\n",
    "            \n",
    "            action_logits_selected = take_vector_elements(action_logits, actions)\n",
    "            \n",
    "            advantages = discounted_r - np.stack(values)[:, 0] \n",
    "            \n",
    "            action_logits_selected = tf.nn.softmax(action_logits_selected)\n",
    "            action_logits_selected_probs = tf.math.log(action_logits_selected)\n",
    "            \n",
    "            action_logits_ = tf.nn.softmax(action_logits)\n",
    "            dist = tfd.Categorical(probs=action_logits_)\n",
    "            action_log_prob = dist.prob(actions)\n",
    "            action_log_prob = tf.math.log(action_log_prob)\n",
    "            \n",
    "            actor_loss = -tf.math.reduce_mean(action_logits_selected_probs * advantages) \n",
    "            \n",
    "            action_probs = tf.nn.softmax(action_logits)\n",
    "            \n",
    "            critic_loss_ = huber_loss(values, discounted_r)\n",
    "            critic_loss = mse_loss(values, discounted_r_)\n",
    "            critic_loss = tf.cast(critic_loss, 'float32')\n",
    "            \n",
    "            total_loss = actor_loss + critic_loss\n",
    "        \n",
    "        #print(\"total_loss: \", total_loss)\n",
    "        #print(\"\")\n",
    "            \n",
    "        grads = tape.gradient(total_loss, self.ActorCritic.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.ActorCritic.trainable_variables))\n",
    "        \n",
    "    def load(self, model_name):\n",
    "        self.ActorCritic = load_model(model_name, compile=False)\n",
    "\n",
    "    def save(self):\n",
    "        self.ActorCritic.save(self.model_name)\n",
    "\n",
    "    pylab.figure(figsize=(18, 9))\n",
    "    def PlotModel(self, score, episode):\n",
    "        self.scores.append(score)\n",
    "        self.episodes.append(episode)\n",
    "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
    "        if str(episode)[-2:] == \"00\":# much faster than episode % 100\n",
    "            pylab.plot(self.episodes, self.scores, 'b')\n",
    "            pylab.plot(self.episodes, self.average, 'r')\n",
    "            pylab.ylabel('Score', fontsize=18)\n",
    "            pylab.xlabel('Steps', fontsize=18)\n",
    "            try:\n",
    "                pylab.savefig(self.path + \".png\")\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        return self.average[-1]\n",
    "    \n",
    "    def imshow(self, image, rem_step=0):\n",
    "        cv2.imshow(self.model_name + str(rem_step), image[rem_step,...])\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "\n",
    "    def GetImage(self, frame, image_memory):\n",
    "        if image_memory.shape == (1,*self.state_size):\n",
    "            image_memory = np.squeeze(image_memory)\n",
    "            \n",
    "        # croping frame to 80x80 size\n",
    "        frame_cropped = frame[35:195:2, ::2,:]\n",
    "        if frame_cropped.shape[0] != self.COLS or frame_cropped.shape[1] != self.ROWS:\n",
    "            # OpenCV resize function \n",
    "            frame_cropped = cv2.resize(frame, (self.COLS, self.ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # converting to RGB (numpy way)\n",
    "        frame_rgb = 0.299*frame_cropped[:,:,0] + 0.587*frame_cropped[:,:,1] + 0.114*frame_cropped[:,:,2]\n",
    "\n",
    "        # convert everything to black and white (agent will train faster)\n",
    "        frame_rgb[frame_rgb < 100] = 0\n",
    "        frame_rgb[frame_rgb >= 100] = 255\n",
    "        \n",
    "        # dividing by 255 we expresses value to 0-1 representation\n",
    "        new_frame = np.array(frame_rgb).astype(np.float32) / 255.0\n",
    "\n",
    "        # push our data by 1 frame, similar as deq() function work\n",
    "        #image_memory = np.roll(image_memory, 1, axis = 0)\n",
    "\n",
    "        # inserting new frame to free space\n",
    "        #image_memory[0,:,:] = new_frame\n",
    "\n",
    "        #return np.expand_dims(image_memory, axis=0)\n",
    "        return np.expand_dims(new_frame, axis=0)\n",
    "\n",
    "    def reset(self, env):\n",
    "        image_memory = np.zeros(self.state_size)\n",
    "        frame = env.reset()\n",
    "        #for i in range(self.REM_STEP):\n",
    "        #    state = self.GetImage(frame, image_memory)\n",
    "        state = self.GetImage(frame, image_memory)\n",
    "            \n",
    "        return state\n",
    "    \n",
    "    def step(self, action, env, image_memory):\n",
    "        next_frame, reward, done, info = env.step(action)\n",
    "        next_state = self.GetImage(next_frame, image_memory)\n",
    "        \n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def train(self, n_threads):\n",
    "        self.env.close()\n",
    "        # Instantiate one environment per thread\n",
    "        envs = [gym.make(self.env_name) for i in range(n_threads)]\n",
    "\n",
    "        # Create threads\n",
    "        threads = [threading.Thread(\n",
    "                target=self.train_threading,\n",
    "                daemon=True,\n",
    "                args=(self,\n",
    "                    envs[i],\n",
    "                    i)) for i in range(n_threads)]\n",
    "\n",
    "        for t in threads:\n",
    "            time.sleep(2)\n",
    "            t.start()\n",
    "            \n",
    "        for t in threads:\n",
    "            time.sleep(10)\n",
    "            t.join()\n",
    "            \n",
    "    def train_threading(self, agent, env, thread):\n",
    "        while self.episode < self.EPISODES:\n",
    "            # Reset episode\n",
    "            score, done, SAVING = 0, False, ''\n",
    "            state = self.reset(env)\n",
    "            \n",
    "            states, actions, rewards, dones = [], [], [], []\n",
    "            core_state = self.ActorCritic.initial_state(1)\n",
    "            while not done:\n",
    "                action, core_state = agent.act(state, core_state)\n",
    "                next_state, reward, done, _ = self.step(action, env, state)\n",
    "                \n",
    "                #print(\"next_state.shape: \", next_state.shape)\n",
    "                #print(\"action: \", action)\n",
    "                #print(\"reward: \", reward)\n",
    "                #print(\"done: \", done)\n",
    "                \n",
    "                states.append(state)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                dones.append(done)\n",
    "\n",
    "                score += reward\n",
    "                state = next_state\n",
    "                    \n",
    "            self.lock.acquire()\n",
    "            self.replay(states, actions, rewards, dones)\n",
    "            self.lock.release()\n",
    "            \n",
    "            states, actions, rewards, dones = [], [], [], []\n",
    "                    \n",
    "            # Update episode count\n",
    "            with self.lock:\n",
    "                average = self.PlotModel(score, self.episode)\n",
    "                # saving best models\n",
    "                if average >= self.max_average:\n",
    "                    self.max_average = average\n",
    "                    #self.save()\n",
    "                    SAVING = \"SAVING\"\n",
    "                else:\n",
    "                    SAVING = \"\"\n",
    "\n",
    "                print(\"episode: {}/{}, thread: {}, score: {}, average: {:.2f} {}\".format(self.episode, self.EPISODES, thread, score, average, SAVING))\n",
    "                if(self.episode < self.EPISODES):\n",
    "                    self.episode += 1\n",
    "\n",
    "        env.close()            \n",
    "\n",
    "    def test(self, Actor_name, Critic_name):\n",
    "        self.load(Actor_name, Critic_name)\n",
    "        for e in range(100):\n",
    "            state = self.reset(self.env)\n",
    "            done = False\n",
    "            score = 0\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = np.argmax(self.Actor.predict(state))\n",
    "                state, reward, done, _ = self.step(action, self.env, state)\n",
    "                score += reward\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, score))\n",
    "                    break\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'PongDeterministic-v4'\n",
    "    #env_name = 'Pong-v0'\n",
    "    agent = A3CAgent(env_name)\n",
    "    \n",
    "    #agent.run() # use as A2C\n",
    "    agent.train(n_threads=1) # use as A3C\n",
    "    #agent.test('Models/Pong-v0_A3C_2.5e-05_Actor.h5', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4aMtoe0fbPg7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pong-v0_A3C_TF2(Working).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
